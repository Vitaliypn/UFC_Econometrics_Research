Result of the OLS model is quite good. Thus its predictions of time are not very accurate (only 14% of data are predicted correctly +-30 sec), but the the model correctly estimates the round when the fight will end in 63% cases and there are 98.6% cases predicted with error just in 1 round - our team considers it as a great result. However, the accuracy score is bad in distinguishing between classes. To use it we need to have a perfect ratio between the amount of classes. It is hard to guarantee that the ratio of all classes, which represents the round where the fight stops, will be perfect (1: 1 : 1 : … : 1). Also we used F1-score. It is equal to 0.33 (for predicting the exact round of stoppage). We can not say that it is quite high or low. Our model can distinguish between classes, but there is some room for improvement. These metrics better describe the situation.

The Logit model is also quite “good”, it can explain near 53% of variance of dependent variables, so in some cases we can state that this model is good. Also to test the quality we use accuracy and F1-score. Accuracy state that the model can correctly predict 87% of outcomes in fight, but we, as we already mentioned, this metric can be quite biase, when our task is distinguish between many classes and we do not have perfect ratio between ratio. We try to reduce this biasness using random sampling for our dataframe, because at the beginning of our research data frame has a strong pattern: Fighter 1 always wins. So to fix it, we randomly swap fighters and their statistics in concrete fights. F1-score, shows 0.87. It indicates accuracy in positive predictions but also there is some very small amount of false positives and missed positives. There's room for improvement, especially in achieving a better balance between precision and recall.